{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "The goal of this question is to get a better understanding of the Poisson\n",
    "distribution and conjugate priors. Assume that we are recording the number of cars\n",
    "crossing an intersection per day for a traffic survey. We have a dataset that consists of\n",
    "the number of cars that have crossed the intersection collected over a period of n days:\n",
    "<div align = \"center\"> $\\{k_1, k_2, ...., k_n\\}$\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to model these counts if we assume they are iid samples from a Poisson\n",
    "distribution: \n",
    "<div align = \"center\"> $\\mathbb{P}(k_i = k) = \\frac{\\lambda^k\\exp(-\\lambda)}{k!}$\n",
    "    </div>\n",
    "where $\\lambda > 0$ is an unknown parameter we wish to determine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Given a random variable $K\\sim Pois(\\lambda)$ compute $\\mathbb{E}[K]$**<br/><br/>\n",
    "$E(K) = \\sum_{k=0}^{\\infty}k \\frac{\\lambda^k e^{-\\lambda}}{k!} = \\sum_{k=1}^{\\infty}k \\frac{\\lambda^k e^{-\\lambda}}{k!}$<br/> <br/>\n",
    "$=\\sum_{k=1}^{\\infty} \\frac{\\lambda^{k-1}\\lambda e^{-\\lambda}}{(k-1)!} = \\lambda e^{-\\lambda}\\sum_{k=1}^{\\infty} \\frac{\\lambda^{k-1}}{(k-1)!} = \\lambda e^{-\\lambda}\\sum_{i=0}^{\\infty} \\frac{\\lambda^{i}}{i!} = \\lambda e^{-\\lambda}e^{\\lambda} = \\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Compute the likelihood of the data $\\mathbb{P}(k_1,k_2,...,k_n|\\lambda)$**<br/><br/>\n",
    "$P(k_1,k_2,...,k_n|\\lambda) = P(k_1|\\lambda) P(k_2|\\lambda) ...... P(k_n|\\lambda)$ <br/><br/>\n",
    "$=\\frac{\\lambda^{k_1}e^{-\\lambda}}{k_1!}\\frac{\\lambda^{k_2}e^{-\\lambda}}{k_2!}.....\\frac{\\lambda^{k_n}e^{-\\lambda}}{k_n!} = \\frac{\\lambda^{k_1+k_2+.....+k_n}  \\exp(-n\\lambda)}{k_1!k_2!....k_n!}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **The maximum likelihood estimator of $\\lambda$ with respect to the collected data.**<br/><br/>\n",
    "To find $\\underset{\\beta}{\\arg\\max} P(k_1,...,k_n|\\lambda)$, it's equivalent to find the log of it.<br/><br/>\n",
    "$\\underset{\\beta}{\\arg\\max} \\log(\\frac{\\lambda^{k_1+k_2+.....+k_n} \\exp(-n\\lambda)}{k_1!k_2!....k_n!}) = \\underset{\\beta}{\\arg\\max} \\log(\\lambda^{k_1+k_2+.....+k_n}\\exp(-n\\lambda))$ <br/><br/>\n",
    "$= \\underset{\\beta}{\\arg\\max} \\log(\\lambda^{k_1+k_2+.....+k_n}) - n\\lambda$<br/><br/>\n",
    "let leftside be $l = \\log(\\lambda^{k_1+k_2+.....+k_n}) - n\\lambda$<br/><br/>\n",
    "$\\frac{\\partial l}{\\partial \\lambda} = \\frac{\\sum_{i=1}^{n}k_i \\lambda^{\\sum k_i - 1}}{\\lambda^{\\sum k_i}} - n = (\\sum_{i=1}^{n}k_i) \\frac{1}{\\lambda} - n = 0$ <br/><br/>\n",
    "$\\lambda = \\frac{\\sum k_i}{n} = E(K)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We noticed the result in part3 is the same as what we get in part1. This intuitively makes sense because the best guess among n trial should the mean of these n trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Now let's put a prior distribution of Gamma on the parameter $\\lambda$**<br/><br/>\n",
    "<div align = \"center\">$\\lambda \\sim Gamma(\\alpha,\\beta)$\n",
    "    </div>\n",
    "for $\\alpha > 0$ and $\\beta>0$ then the pdf of $\\lambda$ is given by:<br/>\n",
    "<div align = \"center\">$P(\\lambda|\\alpha, \\beta) = \\frac{\\beta^{\\alpha}\\lambda^{\\alpha-1}\\exp(-\\beta\\lambda)}{\\Gamma(\\alpha)}$\n",
    "    </div>\n",
    "where\n",
    "<div align = \"center\">$\\Gamma(\\alpha)=\\int_0^{\\infty}x^{\\alpha-1}exp(-x)dx$\n",
    "    </div> <br/>\n",
    "We'll show the posterior distribution of $P(\\lambda|k_1,k_2,......,k_n)$ is a also Gamma distribution ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof: $P(\\lambda|k_1,....,k_n) = \\frac{P(k_1,...,k_n|\\lambda)P(\\lambda)}{P(k_1,....,k_n)} \\propto P(k_1,...,k_n|\\lambda)P(\\lambda)$ <br/><br/>\n",
    "$P(k_1,...,k_n|\\lambda) = \\frac{\\lambda^{(k_1+....+k_n)}\\exp(-n\\lambda)}{k_1!....k_n!}$<br/><br/>\n",
    "$P(\\lambda;\\alpha, \\beta) = \\frac{\\beta^{\\alpha}\\lambda^{\\alpha-1}\\exp(-\\beta\\lambda)}{\\Gamma(\\alpha)}$<br/><br/>\n",
    "Therefore, $P(k_1,...,k_n|\\lambda)P(\\lambda) = \\frac{\\lambda^{(k_1+....+k_n)}\\exp(-n\\lambda)}{k_1!....k_n!}\\frac{\\beta^{\\alpha}\\lambda^{\\alpha-1}\\exp(-\\beta\\lambda)}{\\Gamma(\\alpha)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$=\\frac{\\beta^{\\alpha}}{(k_1!....k_n!)\\Gamma(\\alpha)}\\lambda^{(\\alpha-1)+\\sum k_i} exp[-(n+\\beta)\\lambda] \\propto \\frac{\\beta^{\\alpha}\\lambda^{(\\alpha+\\sum k_i)-1}\\exp(-(n+\\beta)\\lambda)}{\\Gamma(\\alpha)}\\sim Gamma(\\alpha+\\sum k_i, n+\\beta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Compute the maximum a posteriori (MAP) estimate of $\\lambda$**<br/><br/>\n",
    "<div align = \"center\">$\\underset{\\beta}{\\arg\\max}P(\\lambda|k_1,k_2,....,k_n)$\n",
    "    </div> \n",
    "Firstly, $P(\\lambda|k_1,....,k_n)\\propto L = \\beta^{\\alpha}\\lambda^{(\\alpha+\\sum k_i)-1}\\exp(-(n+\\beta)\\lambda)$ <br/><br/>\n",
    "$\\underset{\\beta}{\\arg\\max}P(\\lambda|k_1,k_2,....,k_n) = \\underset{\\beta}{\\arg\\max} \\log L$ <br/><br/>\n",
    "$= \\underset{\\beta}{\\arg\\max}\\log[\\beta^{\\alpha}\\lambda^{(\\alpha+\\sum k_i)-1}\\exp(-(n+\\beta)\\lambda)]$<br/><br/>\n",
    "$= \\underset{\\beta}{\\arg\\max}\\log\\beta^{\\alpha} + \\log\\lambda^{(\\alpha+\\sum k_i-1)} - (n+\\beta)\\lambda$<br/><br/>\n",
    "denote this by $\\underset{\\beta}{\\arg\\max} (Q)$ <br/><br/>\n",
    "$\\Rightarrow \\frac{\\partial Q}{\\partial \\lambda}= \\frac{\\alpha + \\sum k_i - 1}{\\lambda} - (n+\\beta) = 0$ <br/><br/>\n",
    "Therefore, $\\hat \\lambda_{MAP} = \\frac{\\alpha + \\sum k_i -1}{n+\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "$\\hat \\lambda_{MAP}$ is positive correlates to $\\frac{\\sum k_i -1}{n} \\sim$ average # car perday, which makes sense, since with higher average observed, the distribution parameter $\\lambda$ is expected to shift postively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
